---
title: "Contrastes de hipótesis. Enfoque de Neyman-Pearson"
author: "Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir"
date: ""
lang: es-ES
output:
  beamer_presentation:
#    colortheme: rose
    incremental: yes
    theme: Rochester
    toc: no


header-includes: \usepackage{amsmath,color,array,booktabs,algorithm2e}
                 \newcommand\blue[1]{\textcolor{blue}{#1}}
                 \newcommand\red[1]{\textcolor{red}{#1}}
                 

                 
              
---


# Enfoque de Neyman-Pearson


## Introducción 

* En esta presentación vamos a introducir los \red{contrastes de hipótesis} desde una perspectiva más amplia.

* Esta nueva perspectiva nos permitirá introducir la \red{clasificación} en \red{machine learning} y 
\red{detección en procesamiento de señales.}

* Este nuevo enfoque se llama \red{enfoque de Neyman-Pearson.}

## Distribuciones de las hipótesis nula y alternativa

* En los \blue{contrastes de hipótesis paramétricos} introducidos durante el curso, nos concentramos en la \red{hipótesis nula $H_0$.}

* Tanto si usamos los \red{z-test} como los \red{t-test}, en el cálculo del \red{p-valor}, se usaba la distribución suponiendo que la \red{hipótesis nula $H_0$} es cierta.


## Distribuciones de las hipótesis nula y alternativa
* Para fijar ideas, suponiendo que el contraste considerado era sobre la \red{media $\mu$}, y el contraste era de la forma:
$$
\left.
\begin{array}{ll}
H_0:\mu  & =\mu_0,\\
H_1: \mu & \neq (<,>)\mu_0,
\end{array}
\right\}
$$
donde hemos considerados los tres casos de \red{hipótesis alternativa $H_1$}, suponiendo que la \blue{desviación típica $\sigma$} de la población es conocida, suponemos que la distribución del \red{estadístico de contraste} $Z=\frac{\overline{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}$ es una \red{normal estándar} o $N(0,1)$ suponiendo que la \blue{hipótesis nula $H_0$ es cierta} o que $\mu =\mu_0$ 

## Distribuciones de las hipótesis nula y alternativa
* La suposición anterior es equivalente a suponer que la distribución de la \red{media muestral $\overline{X}$} es \red{normal} de \red{parámetros} $\mu_{\overline{X}} =\mu_0$ y $\sigma_{\overline{X}}=\frac{\sigma}{\sqrt{n}}$: $\overline{X}=N\left(\mu_0,\frac{\sigma}{\sqrt{n}}\right).$

* Recordemos que para \red{aceptar} o \red{rechazar} la \blue{hipótesis nula $H_0$}, comparamos el valor crítico $z_{\alpha} (H_1:\mu <\mu_0)$, $z_{1-\alpha} (H_1:\mu > \mu_0)$, $z_{1-\frac{\alpha}{2}} (H_1:\mu \neq \mu_0)$ con el valor $Z$ del \red{estadístico de contraste} y dependiendo de dicha comparación aceptamos o rechazamos la \blue{hipótesis nula $H_0$}, siendo $\alpha$ el \red{nivel de significación.}

## Distribuciones de las hipótesis nula y alternativa

* Concretamente,
    * Si $H_1:\mu <\mu_0$, 
        * si \red{$Z<z_\alpha$}, \red{rechazamos $H_0$} y en caso contrario, aceptamos $H_0$,
    * Si $H_1:\mu > \mu_0$, 
        * si \red{$Z > z_{1-\alpha}$}, \red{rechazamos $H_0$} y en caso contrario, aceptamos $H_0$,
    * Si $H_1:\mu \neq \mu_0$, 
        * si \red{$|Z|>z_{1-\frac{\alpha}{2}}$}, \red{rechazamos $H_0$} y en caso contrario, aceptamos $H_0$.

* Un aspecto importante del \blue{contrate de hipótesis} es la \red{hipótesis alternativa $H_1$}, donde si suponemos que es cierta, la distribución del \red{estadístico de contraste} $Z$ o $\overline{X}$ (dependiendo de cuál usemos) sería diferente. 



## Distribuciones de las hipótesis nula y alternativa
* Concretamente, si la \red{hipótesis alternativa $H_1$} es cierta, la distribución  del \red{estadístico de contraste} $\overline{X}$ sería $\overline{X}=N\left(\mu,\frac{\sigma}{\sqrt{n}}\right)$ o $Z=\frac{\overline{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}=N\left(\frac{\mu-\mu_0}{\frac{\sigma}{\sqrt{n}}},1\right)$.

* Para usar ambas distribuciones, definimos:
$$
f_0(z)=f_{Z}(z|H_0),\quad f_1(z)=f_{Z}(z|H_1),
$$
las \blue{funciones de densidad} del \red{estadístico de contraste} suponiendo que $H_0$ es cierta ($f_0(z)$) o suponiendo que $H_1$ es cierta ($f_1(z)$).

* En el primer caso o suponiendo que \red{$H_0$ es cierta}, $f_0(z)$ sería la \blue{función de densidad} de una $N\left(0,1\right)$ y en el segundo caso o suponiendo que \red{$H_1$ es cierta}, $f_1(z)$ sería la \blue{función de densidad} de una $N\left(\frac{\mu-\mu_0}{\frac{\sigma}{\sqrt{n}}},1\right)$.

## Distribuciones de las hipótesis nula y alternativa. Ejemplo

* Suponemos que nos planteamos el contraste de hipótesis siguiente:
$$
\left.
\begin{array}{ll}
H_0:\mu  & =2,\\
H_1: \mu & > 2,
\end{array}
\right\}
$$
* En el gráfico siguiente hemos dibujado las \blue{funciones de densidad} $f_0$ y $f_1$. La curva azul es $f_0$ y la roja $f_1$, donde hemos supuesto que $\mu=2.5$ y $\sigma = 2$.

* \red{Rechazaremos la hipótesis nula $H_0$} si el valor del \red{estadístico de contraste $Z$} se encuentra en la zona verde, o $Z>z_{1-\alpha}$, donde hemos considerado un \red{nivel de significación $\alpha=0.05$}, de donde $z_{0.95}=`r round(qnorm(0.95),3)`$. 

## Distribuciones de las hipótesis nula y alternativa. Ejemplo

```{r,echo=FALSE,fig.align='center',fig.height=3.75,fig.width=4.25}
x=seq(from=-4,to=6,by=0.01)
plot(x,dnorm(x),type="l",col="blue",xlab="z",ylab=expression(f[i](z)))
lines(x,dnorm(x,(2.5-2)/(2/sqrt(50)),1),col="red")
alfa=0.05
x2=seq(from=qnorm(1-alfa),to=6,by=0.001)
for (i in 1:length(x2)){lines(c(x2[i],x2[i]),c(0,dnorm(x2[i])),col="green")}
text(x2[1],0.035,expression(z[1-alpha]))
points(x2[1],0,cex=0.5,col="red",pch=19)

```

## Reglas de decisión
* Un \blue{contraste de hipótesis}, se basa en una \red{regla de decisión $\delta(\cdot)$} a partir de un \red{espacio de valores} ${\cal Z}$ del \red{estadístico de contraste} $Z$.

* Concretamente, en un contraste de la \red{media $\mu$} del tipo:
$$
\left.
\begin{array}{ll}
H_0:\mu  & =\mu_0,\\
H_1: \mu & > \mu_0,
\end{array}
\right\}
$$
como la del ejemplo anterior,
    * el \red{espacio de valores} ${\cal Z}$ sería el \blue{conjunto de números reales} $\mathbb{R}$,
    * el \red{estadístico de contraste} $Z$ sería $Z=\frac{\overline{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}$ (suponemos $\sigma$ conocida) y
    * la \red{regla de decisión $\delta(z,\alpha)$} que depende del valor del \red{estadístico de contraste} y del \red{nivel de significación} $\alpha$ sería: 
        * si $Z\geq z_{1-\alpha}$, \red{rechazamos la hipótesis nula $H_0$},
        * si $Z< z_{1-\alpha}$, \red{aceptamos la hipótesis nula $H_0$}.
        
## Reglas de decisión
* Escribiremos la \red{regla de decisión} de la forma siguiente:
$$
\delta(z,\alpha)=\begin{cases}
1, & \mbox{ si }z\in R_\alpha (\mbox{ rechazamos }H_0),\\
0, & \mbox{ si }z\not\in R_\alpha (\mbox{ aceptamos }H_0),\\
\end{cases}
$$
donde $R_\alpha$ es la llamada \red{zona de rechazo} que valdría en el ejemplo que vamos desarrollando:
$$
R_\alpha = \{z \geq z_{1-\alpha}=\phi^{-1}(1-\alpha)\},
$$
donde $\phi(z)$ representa la \red{función de distribución} de la $N(0,1)$: $\phi(z)=P(Z\leq z)$.

## Ejemplo anterior
* En el ejemplo anterior, la \red{regla de decisión} para $\alpha =0.05$ sería:
$$
\delta(z,0.05)=\begin{cases}
1, & \mbox{ si }z\in R_{0.05} (\mbox{ rechazamos }H_0),\\
0, & \mbox{ si }z\not\in R_{0.05} (\mbox{ aceptamos }H_0),\\
\end{cases}
$$
donde $R_{0.05} = \{z \geq z_{0.95}=\phi^{-1}(0.95)=`r round(qnorm(0.95),3)`\}.$


## Errores tipo I y tipo II
* Recordemos que en un \blue{contraste de hipótesis}, el \red{error tipo I} se definía como:
$$
\mbox{Error tipo I}=P(\mbox{Rechazar }H_0|H_0\mbox{ cierta }),
$$
o como la \red{probabilidad de rechazar la hipótesis nula suponiendo ésta cierta.}

* De la misma manera, el \red{error tipo II} se definía como:
$$
\mbox{Error tipo II}=P(\mbox{Aceptar }H_0|H_0\mbox{ falsa }),
$$
o como la \red{probabilidad de aceptar la hipótesis nula suponiendo ésta falsa.}

## Errores tipo I y tipo II
* Si interpretamos un \blue{contraste de hipótesis} como un \red{proceso de decisión}, 
    * aceptar la \red{hipótesis nula} sería tener un valor \red{negativo} y 
    * \red{rechazarla} sería tener un valor \red{positivo.}

* Entonces, podemos interpretar
    * el \red{error tipo I} como un \red{falso positivo} ya que declaramos \red{positiva} una decisión que debería ser \red{negativa} y    
    * y el \red{error tipo II} como un \red{falso negativo} ya que declaramos \red{negativa} una decisión que debería ser \red{positiva}.
    
## Tasa de falsos positivos y falsos negativos
* En un contexto del \red{proceso de decisión}, 
    * el \red{error tipo I} se podría interpreta como la \red{tasa de falsos positivos} y
    * el \red{error tipo II} se podría interpreta como la \red{tasa de falsos negativos}.
    
* Otro concepto que se introdujo en los \blue{contrastes de hipótesis} es la \red{potencia de un contraste} que se definía como:
\begin{align*}
\mbox{Potencia de un contraste} & =1-\mbox{Error tipo II}\\ & =1-P(\mbox{Aceptar }H_0|H_0\mbox{ falsa })\\ & =P(\mbox{rechazar }H_0|H_0\mbox{ falsa}),
\end{align*}
es decir, como la \red{probabilidad de rechazar la hipótesis nula suponiendo ésta falsa.}


## Tasa de verdaderos positivos
* En un contexto del \red{proceso de decisión}, la \red{potencia del contraste} se puede interpretar como la \red{probabilidad de detectar un negativo}. 

* Por tanto, la \red{potencia de un contraste} puede interpretarse como la \red{tasa de verdaderos positivos} o la \red{probabilidad de detección.}

* En el gráfico siguiente mostramos en amarillo el \red{error tipo II} o la \red{tasa de falsos negativos} para el ejemplo anterior. Recordemos que en verde está el \red{error tipo I} o la \red{tasa de falsos positivos.}

## Tasa de verdaderos positivos
```{r,echo=FALSE,fig.align='center',fig.height=3.75,fig.width=4.25}
x=seq(from=-4,to=6,by=0.01)
plot(x,dnorm(x),type="l",col="blue",xlab="x",ylab=expression(f[i](x)))
lines(x,dnorm(x,(2.5-2)/(2/sqrt(50)),1),col="red")
alfa=0.05
x2=seq(from=qnorm(1-alfa),to=6,by=0.001)
for (i in 1:length(x2)){lines(c(x2[i],x2[i]),c(0,dnorm(x2[i])),col="green")}
x3=seq(from=-4,to=qnorm(1-alfa),by=0.001)
for (i in 1:length(x3)){lines(c(x3[i],x3[i]),c(0,dnorm(x3[i],(2.5-2)/(2/sqrt(50)),1)),col="yellow")}

text(x2[1],0.02,expression(z[1-alpha]))
points(x2[1],0,cex=0.5,col="red",pch=19)
lines(x,dnorm(x),col="blue")
lines(x,dnorm(x,(2.5-2)/(2/sqrt(50)),1),col="red")


```


## Tasa de falsos positivos, falsos negativos y verdaderos positivos

* Matemáticamente, podemos escribir las tasas anteriores de la forma siguiente:
    * \red{Tasa de falsos positivos o error tipo I:}
$$
P_{FP}=\int_{R_\alpha}f_0(z)\,dz =\int_{z_{1-\alpha}}^\infty f_0(z)\, dz.
$$
     * \red{Tasa de falsos negativos o error tipo II:}
$$
P_{FN}=\int_{R_\alpha^c}f_1(z)\,dz =\int_{-\infty}^{z_{1-\alpha}} f_1(z)\, dz.
$$
     * \red{Tasa de verdaderos positivos o potencia del contraste:}
$$
P_{VP}=\int_{R_\alpha}f_1(z)\,dz =\int_{z_{1-\alpha}}^\infty f_1(z)\, dz=1-P_{FN}.
$$

## Tasa de falsos positivos, falsos negativos y verdaderos positivos
* Podemos escribir las probabilidades anteriores en función de la \red{regla de decisión $\delta(z,\alpha)$} de la forma siguiente:
\begin{align*}
P_{FP}& =\int_{\mathbb{R}}\delta(z,\alpha) f_0(z)\,dz =\int_{z_{1-\alpha}}^\infty f_0(z)\, dz,\\
P_{FN}& =\int_{\mathbb{R}}(1-\delta(z,\alpha)) f_1(z)\,dz =\int_{-\infty}^{z_{1-\alpha}} f_1(z)\, dz,\\
P_{VP}& =\int_{\mathbb{R}}\delta(z,\alpha) f_1(z)\,dz =\int_{z_{1-\alpha}}^\infty f_1(z)\, dz.
\end{align*}

## Ejemplo anterior
* En el ejemplo anterior, las tasas de \red{falsos positivos, falsos negativos y verdaderos positivos} son las siguientes:
\begin{align*}
P_{FP}& =\int_{`r round(qnorm(0.95),3)`}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}}\, dz=1-\phi(`r round(qnorm(0.95),3)`)=0.05,\\
P_{FN}& =\int_{-\infty}^{`r round(qnorm(0.95),3)`} \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{\left(z-\frac{2.5-2}{\frac{2}{\sqrt{50}}}\right)^2}{2}}\, dz=\int_{-\infty}^{`r round(qnorm(0.95),3)`} \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{(z-`r round((2.5-2)/(2/sqrt(50)),3)`)}{2}}\, dz\\ & = P(N(`r round((2.5-2)/(2/sqrt(50)),3)`,1)\leq `r round(qnorm(0.95),3)`)=\phi(`r round(qnorm(0.95),3)`-`r round((2.5-2)/(2/sqrt(50)),3)`)=\phi(`r round(qnorm(0.95)-(2.5-2)/(2/sqrt(50)),3)`)\\ & = `r round(pnorm(qnorm(0.95)-(2.5-2)/(2/sqrt(50))),3)`,\\
P_{VP}& =1-P_{FN}=1-`r round(pnorm(qnorm(0.95)-(2.5-2)/(2/sqrt(50))),3)`=`r round(pnorm(qnorm(0.95)-(2.5-2)/(2/sqrt(50)),lower.tail=F),3)`.
\end{align*}

## Decisión de Neyman-Pearson
* Una vez establecidos los conceptos necesarios, el objetivo es hallar la mejor \red{regla de decisión} para un \blue{contraste de hipótesis.}

* Definimos la \red{regla de decisión de Neyman-Pearson} precisamente como la mejor \red{regla de decisión} donde formalmente se define como el siguiente \red{problema de optimización:}

\begin{definition}
La \red{regla de decisión de Neyman-Pearson} se define como el siguiente problema de \red{optimización:}
$$
\hat{\delta}=\max_{\delta \mbox{ tal que }P_{FP}(\delta)\leq \alpha} P_{VP}(\delta)
$$
\end{definition}

## Decisión de Neyman-Pearson
* Es decir, de entre todas las \red{reglas de decisión $\delta$} tal que la \red{tasa de falsos positivos} es menor que un cierto \red{nivel de significación $\alpha$}, hallar la que \red{maximiza} la \red{tasa de verdaderos positivos} o la \red{tasa de detección.}

* Para resolver el problema de \red{optimización} anterior, necesitamos introducir el \red{índice de verosimilitud} entre dos distribuciones de \blue{funciones de densidad} $f_0(z)$ y $f_1(z)$ como:
$$
L(z)=\frac{f_1(z)}{f_0(z)}.
$$

## Decisión de Neyman-Pearson
* El siguiente resultado resuelve el problema de \red{optimización:}
\begin{theorem}
La solución al problema de \red{optimización de la regla de decisión de Neyman-Pearson} es el siguiente:
$$
\hat{\delta}(z)=\begin{cases}
1, & \mbox{ si }L(z)\geq \eta,\\
0, & \mbox{ si }L(z) <\eta,
\end{cases}
$$
donde $\eta$ depende del \red{nivel de significación} $\alpha$.
\end{theorem}

* El teorema anterior dice que si el objetivo es maximizar  la \red{tasa de detección} o la \red{tasa de verdaderos positivos} manteniendo la \red{tasa de falsos positivos}, no podemos hacerlo mejor que la \red{regla de decisión} dada por el Teorema.

## Demostración del Teorema
* La relación entre $\eta$ y $\alpha$ es la siguiente:
$$
\alpha  = P_{FP}(\hat{\delta})=\int_\mathbb{R} \hat{\delta}(z) f_0(z)\, dz =\int_{L(z)\geq \eta} f_0(z)\, dz
$$

* Sea $\delta$ otra regla de decisión. 
Nuestro objetivo es demostrar que $P_{VP}(\hat{\delta})\geq P_{VP}(\delta)$.

* Como la regla $\delta$ debe cumplir que la tasa de falsos positivos debe ser menor que $\alpha$, tenemos que:
\begin{align*}
\alpha & \geq P_{FP}(\delta) =\int_\mathbb{R} \delta(z) f_0(z)\, dz\\ & = \int_{L(z)\geq \eta} \delta(z) f_0(z)\, dz + \int_{L(z)< \eta} \delta(z) f_0(z)\, dz.
\end{align*}

## Demostración del Teorema (continuación)
* Entonces:
\begin{align*}
& \int_{L(z)\geq \eta}  f_0(z)\, dz \geq  \int_{L(z)\geq \eta} \delta(z) f_0(z)\, dz + \int_{L(z)< \eta} \delta(z) f_0(z)\, dz,\ \Rightarrow\\
& \int_{L(z)\geq \eta} (1-\delta(z))f_0(z)\, dz - \int_{L(z)< \eta} \delta(z) f_0(z)\, dz\geq 0.
\end{align*}

* A continuación, veamos que $P_{VP}(\hat{\delta})\geq P_{VP}(\delta)$:
\begin{align*}
P_{VP}(\hat{\delta})&  =\int_\mathbb{R}\hat{\delta}(z) f_1(z)\, dz =\int_{L(z)\geq \eta}f_1(z)\, dz,\\
P_{VP}(\delta) & =\int_\mathbb{R}\delta(z) f_1(z)\, dz =\int_{L(z)\geq \eta}\delta(z)f_1(z)\, dz \\ & \qquad\qquad +\int_{L(z)< \eta}\delta(z)f_1(z)\, dz ,\\
\end{align*}

## Demostración del Teorema (continuación)
* Restando las dos expresiones anteriores,
$$
P_{VP}(\hat{\delta})-P_{VP}(\delta) = \int_{L(z)\geq \eta}(1-\delta(z))f_1(z)\, dz-\int_{L(z)< \eta}\delta(z)f_1(z)\, dz
$$

* Ahora bien, 
    * si $L(z)=\frac{f_1(z)}{f_0(z)}\geq \eta$, $f_1(z)\geq \eta f_0(z)$,
    * si $L(z)=\frac{f_1(z)}{f_0(z)}< \eta$, $f_1(z) < \eta f_0(z)$ y por tanto, $-f_1(z) > -\eta f_0(z)$.

## Demostración del Teorema (continuación)
* Entonces:
\begin{align*}
& P_{VP}(\hat{\delta})-P_{VP}(\delta) \geq  \int_{L(z)\geq \eta}(1-\delta(z))\eta f_0(z)\, dz\\ & \qquad\qquad -\int_{L(z)< \eta}\eta \delta(z)f_0(z)\, dz\\ & =\eta\left(\int_{L(z)\geq \eta}(1-\delta(z)) f_0(z)\, dz-\int_{L(z)< \eta} \delta(z)f_0(z)\, dz\right)
\end{align*}

* Anteriormente vimos que 
$$
\int_{L(z)\geq \eta}(1-\delta(z)) f_0(z)\, dz-\int_{L(z)< \eta} \delta(z)f_0(z)\, dz \geq 0,
$$
por tanto,
$$
P_{VP}(\hat{\delta})-P_{VP}(\delta) \geq 0,
$$
tal como queríamos demostrar.

## Decisión de Neyman-Pearson. Ejemplo
* Ahora ya sabemos cómo hallar \red{reglas de decisión óptimas} dado un \blue{contraste de hipótesis}.

* Apliquemos el Teorema anterior al ejemplo desarrollado pero lo haremos con cualquier valor de $\sigma$.

* En el ejemplo, 
$$
f_0(z)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}},\quad f_1(z)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{\frac{-\left(z-\frac{\mu-2}{\frac{\sigma}{\sqrt{n}}}\right)^2}{2}}
$$ 

* Sea $\mu_1 = \frac{\mu-2}{\frac{\sigma}{\sqrt{n}}}$. El valor de $L(z)$ será:
$$
L(z)=\frac{f_1(z)}{f_0(z)}=\mathrm{e}^{-\frac{(z-\mu_1)^2}{2}+\frac{z^2}{2}}=\mathrm{e}^{\frac{1}{2}(2z\mu_1-\mu_1^2)}.
$$

## Decisión de Neyman-Pearson. Ejemplo
* La condición $L(z)\geq \eta$ será en nuestro caso,
$$
\mathrm{e}^{\frac{1}{2}(2z\mu_1-\mu_1^2)}\geq \eta,\ \Leftrightarrow 2z\mu_1\geq 2\ln(\eta)+\mu_1^2,\ \Leftrightarrow z\geq \frac{2\ln(\eta)+\mu_1^2}{2\mu_1}:=\tau.
$$

* Para hallar $\tau$ en función de $\alpha$, hay que tener en cuenta que:
$$
\alpha  = P_{FP}(\hat{\delta})=\int_{L(z)\geq \eta} f_0(z)\, dz =\int_\tau^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}}\, dz =1-\phi(\tau).
$$

* Entonces,
$$
\phi(\tau)=1-\alpha,\ \Leftrightarrow \tau =\phi^{-1}(1-\alpha).
$$


## Decisión de Neyman-Pearson. Ejemplo
* En pocas palabras la \red{regla de decisión óptima} sería 
    * si $z\geq \phi^{-1}(1-\alpha)=z_{1-\alpha}$, rechazamos la hipótesis nula y,
    * si $z< \phi^{-1}(1-\alpha)=z_{1-\alpha}$, aceptamos la hipótesis nula.
    
* La regla anterior es la regla que aprendimos. En este nuevo enfoque, hemos demostrado cuál es la razón que sea la \red{regla de decisión óptima.}


# Curva ROC

## Introducción
* Como ya hemos comentado, realizar un \blue{contraste de hipótesis} es similar a realizar una \red{clasificación en dos clases.} 

* \red{Rechazar la hipótesis nula} sería equivalente a \red{clasificar} como \red{positivo} y \red{aceptar la hipótesis nula}, como \red{negativo.}

* Entonces, cualquier \red{métrica de evaluación} para \blue{contrastes de hipótesis} tiene su equivalencia en \red{clasificación} y viceversa.

* Vamos a introducir la curva *Receiving Operating Characteristic* o curva ROC. Dicha curva es una de las    \red{métricas} más usadas en tareas de \red{clasificación, detección y segmentación} en \red{machine learning.}

## Introducción
* Vamos a relacionar el \red{enfoque de Neyman Pearson} para \blue{contrastes de hipótesis} y las \red{curvas ROC.}

* Recordemos que el \red{criterio de Neyman-Pearson} es la \red{regla de decisión óptima $\hat{\delta}$} que resuelve el problema de \red{optimización} siguiente:
$$
\hat{\delta}=\max_{\delta \mbox{ tal que }P_{FP}(\delta)\leq \alpha} P_{VP}(\delta)
$$

* La \red{regla de decisión óptima $\hat{\delta}$} cambia si cambiamos el \red{nivel de significación} $\alpha$. Por tanto, podemos escribir $\hat{\delta}(\alpha)$.

## Curva ROC
* Entonces, dados un conjunto de \red{niveles de significación} $\alpha_1,\ldots,\alpha_N$, podemos calcular las \red{reglas de decisión óptimas} $\hat{\delta}_1,\ldots,\hat{\delta}_N$ correspondientes a dichos niveles de significación.

* Además, para cada \red{regla de decisión óptima} $\hat{\delta}_i$, podemos calcular la \red{tasa de falsos positivos} $P_{FP}(\hat{\delta}_i)$ y la \red{tasa de verdaderos positivos} $P_{VP}(\hat{\delta}_i)$, $i=1,\ldots,N$.

* El gráfico de las \red{tasas de verdaderos positivos} $P_{VP}(\hat{\delta}_i)$ (eje $Y$) como función de las \red{tasas de falsos positivos} $P_{FP}(\hat{\delta}_i)$ (eje $X$), $i=1,\ldots,N$ se denomina \red{curva ROC} para el contraste de hipótesis considerado. 

## Curva ROC. Ejemplo
* Para el ejemplo considerado, dado un valor de $\alpha\in [0,1]$, la \red{tasa de falsos positivos} $P_{FP}(\hat{\delta})$ y la \red{tasa de verdaderos positivos} $P_{VP}(\hat{\delta})$ para dicho valor de $\alpha$ serán:
\begin{align*}
P_{FP}& =\int_{\phi^{-1}(1-\alpha)}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}}\, dz=1-\phi(\phi^{-1}(1-\alpha))=\alpha,\\
P_{FN}& =\int_{-\infty}^{\phi^{-1}(1-\alpha)} \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{\left(z-\frac{2.5-2}{\frac{2}{\sqrt{50}}}\right)^2}{2}}\, dz\\ & =\int_{-\infty}^{\phi^{-1}(1-\alpha)} \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{(z-`r round((2.5-2)/(2/sqrt(50)),3)`)}{2}}\, dz\\ & = P(N(`r round((2.5-2)/(2/sqrt(50)),3)`,1)\leq \phi^{-1}(1-\alpha))=\phi(\phi^{-1}(1-\alpha)-`r round((2.5-2)/(2/sqrt(50)),3)`),\\
P_{VP}& =1-P_{FN}=1-\phi(\phi^{-1}(1-\alpha)-`r round((2.5-2)/(2/sqrt(50)),3)`).
\end{align*}

## Curva ROC. Ejemplo
* El gráfico siguiente muestra la \red{curva ROC} para el ejemplo considerado.




## Curva ROC. Ejemplo
```{r,echo=FALSE}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,type="l",xlab=expression(P[FP]),ylab=expression(P[VP]),main="Curva ROC",col="red")
```

## Interpretación de la curva ROC
* El valor $(0,0)$ siempre está en la \red{curva ROC}. Significa que se tiene una tasa nula de \red{falsos positivos} y \red{verdaderos positivos}. En este caso, siempre aceptamos la \blue{hipótesis nula} pero tampoco se \red{detecta nada} ya que nunca aceptamos la \blue{hipótesis alternativa $H_1$}. Estaríamos en un caso sin \red{ningún tipo de interés} desde el punto de vista de realizar un \blue{contraste de hipótesis} o de realizar una \red{clasificación en dos clases.}

* El valor $(1,1)$ también pertenece siempre a la \red{curva ROC}. Significa que se tiene un $100\%$ de \red{falsos positivos} y un $100\%$ de \red{verdaderos positivos.} En este caso, siempre rechazamos la \blue{hipótesis nula}, por tanto, tenemos un $100\%$ de detección pero al mismo tiempo tenemos una tasa del $100\%$ de \red{falsos positivos} o un \red{error tipo I} máximo. 


## Interpretación de la curva ROC

* Para cualquier valor de $\alpha$ diferente de $0$ y $1$, no podemos tener una \red{tasa de verdaderos positivos} más alta que la que nos da la \red{curva ROC} para la \red{tasa de falsos positivos} fijada.

* La \red{curva ROC} dice cómo cambia la \red{regla de decisión} a medida que cambiamos el \red{umbral}. Dicho \red{umbral} es un concepto usado tanto en \blue{contraste de hipótesis} como en \red{clasificación.}

* En \blue{contraste de hipótesis}, el \red{umbral} sería el \red{nivel de significación $\alpha$.} En \red{clasificación}, el \red{umbral} sería un valor para decidir si un valor de la muestra se clasifica como \red{clase $1$} o \red{clase $0$.}

## Interpretación de la curva ROC
* La \red{curva ROC ideal} sería aquella en la cual la \red{tasa de falsos positivos} siempre es nula, $P_{FP}=0$ y la \red{tasa de verdaderos positivos} siempre vale $1$ o su valor máximo, $P_{VP}=1$. En el gráfico, la curva correspondería a los lados del cuadrado que van de $(0,0)$ a $(0,1)$ y de $(0,1)$ a $(1,1)$. Sin embargo, esta situación es teórica y nunca se da en la práctica.


## Decisión ciega
* Imaginemos que para realizar un \red{contraste de hipótesis} determinado, consideramos la \red{regla de decisión} que consiste en \red{rechazar la hipótesis nula $H_0$} con probabilidad $\alpha$ y \red{aceptarla} con probabilidad $1-\alpha$. Es decir:
$$
\delta(z)=\begin{cases}1, & \mbox{ con probabilidad }\alpha,\\
0, & \mbox{ con probabilidad }1-\alpha.\end{cases}
$$
Llamamos a dicha regla de decisión, \red{decisión ciega} ya que no depende del valor del \red{estadístico de contraste.}


## Decisión ciega

* En este caso, fijado un valor del \red{nivel de significación} $\alpha$, la \red{tasa de falsos positivos} y la \red{tasa de verdaderos positivos} serán 
\begin{align*}
P_{FP} & = P(\mbox{ rechazar }H0|H0\mbox{ cierta})=\alpha,\\
P_{VP} & = P(\mbox{ rechazar }H0|H0\mbox{ cierta})=\alpha.
\end{align*}
Es decir el punto de la \red{curva ROC} de la \red{decisión ciega} sería $(\alpha,\alpha)$.

* Por tanto, la \red{curva ROC} correspondiente a la \red{decisión ciega} sería la \red{diagonal del cuadrado $[0,1]\times [0,1]$.}

* Entonces, cuanto más lejos esté la \red{curva ROC} de nuestra \red{regla de decisión} de la \red{diagonal} del cuadrado $[0,1]\times [0,1]$, más lejos estará de la \red{decisión ciega} y más \red{óptima} será.

## Decisión ciega
```{r,echo=FALSE}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,type="l",xlab=expression(P[FP]),ylab=expression(P[VP]),main="Curva ROC",col="blue")
text(0.25,0.75,"Neyman-Pearson",col="blue")
lines(c(0,1),c(0,1),col="red")
text(0.5,0.45,srt=33,"Decisión ciega",col="red")
```


## Evaluación de la regla de decisión a través de la curva ROC
* Para evaluar una \red{regla de decisión} dada su \red{curva ROC} se calcula el \red{AUC} (*area under the curve*) o el \red{área bajo la curva} ya que cuánto mayor es dicha área, más cerca está la curva ROC de la \red{curva ROC ideal.}

* En general, para dibujar la curva ROC se dispone de un \red{conjunto discreto} de valores del tipo $(P_{FP,i}),P_{VP,i})$, $i=1,\ldots,N$. Entonces una aproximación del \red{área bajo la curva AUC} se puede calcular de la forma siguiente:
$$
\mbox{AUC}\approx \frac{1}{2}\sum_{i=1}^{N-1} (P_{VP,i+1}+P_{VP,i})\cdot (P_{FP,i+1}-P_{FP,i}).
$$


## AUC
```{r,echo=FALSE,fig.align='center'}
alphas = seq(from=0,to=1,by=0.1)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,type="l",xlab=expression(P[FP]),ylab=expression(P[VP]),main="Curva ROC",col="blue")
for (i in 2:(length(alphas)-1)){
  polygon(c(tasas.falsos.positivos[i],tasas.falsos.positivos[i+1],tasas.falsos.positivos[i+1],tasas.falsos.positivos[i]),
          c(0,0,tasas.verdaderos.positivos[i+1],tasas.verdaderos.positivos[i]),col="red",lty=3)
}
polygon(c(0,tasas.falsos.positivos[2],tasas.falsos.positivos[2],0),c(0,0,tasas.verdaderos.positivos[2],0),col="red",lty=3)
```


## Ejemplo anterior
* En el ejemplo anterior, considerando $N=11$ puntos, con 
\begin{align*}
P_{FP,i} & =`r tasas.falsos.positivos`,\\
P_{VP,i} & = `r round(tasas.verdaderos.positivos[1:7],4)`,\\
&\qquad  `r round(tasas.verdaderos.positivos[8:11],4)`.\\
\end{align*}

* La aproximación del \red{área AUC} sería:
\begin{align*}
\mbox{AUC} & \approx \frac{1}{2}\sum_{i=1}^{10} (P_{VP,i+1}+P_{VP,i})\cdot (P_{FP,i+1}-P_{FP,i})\\ & =
\frac{1}{2}((`r round(tasas.verdaderos.positivos[2],4)`+`r round(tasas.verdaderos.positivos[1],4)`)\cdot (`r tasas.falsos.positivos[2]`-`r tasas.falsos.positivos[1]`)+\cdots + (`r round(tasas.verdaderos.positivos[11],4)`+`r round(tasas.verdaderos.positivos[10],4)`)\cdot (`r tasas.falsos.positivos[11]`-`r tasas.falsos.positivos[10]`))\\ & = `r round(0.5*(sum((tasas.verdaderos.positivos[2:11]+tasas.verdaderos.positivos[1:10])*(tasas.falsos.positivos[2:11]-tasas.falsos.positivos[1:10]))),4)`. 
\end{align*}

## Ejemplo anterior
* Como el valor máximo del \red{área AUC} es $1$ que correspondería a la \red{curva ROC ideal} y el valor mínimo vale $0.5$ que correspondería a la \red{decisión ciega}, la \red{regla de decisión} es bastante buena.

## La curva *Precision-Recall*
* Una alternativa a la \red{curva ROC} para medir el rendimiento de la \red{regla de decisión} es la \red{curva Precision-Recall} o \red{curva PR}. Se define de la forma siguiente:

\begin{definition}
Se define la \red{precisión} de una \red{regla de decisión} como:
$$
\mbox{precisión} = \frac{P_{VP}}{P_{VP}+P_{FP}},
$$
y el \red{recall} como:
$$
\mbox{recall} = \frac{P_{VP}}{P_{VP}+P_{FN}}=P_{VP}.
$$
\end{definition}

## La curva *Precision-Recall*
* Es decir, la \red{precisión} sería el número de \red{verdaderos positivos} entre todos los \red{verdaderos positivos y falsos positivos} o el \red{total de positivos detectados}.

* Una \red{precisión alta} significa que entre todos los \red{positivos detectados}, la mayoría son \red{verdaderos positivos}. Es decir, lo que la \red{regla de decisión} afirma que son positivos, en realidad la mayoría lo son o la \red{regla} es muy fiable. En este caso, si \red{rechazamos la hipotesis nula}, probablemente tomemos una buena decisión.

* Una \red{precisión baja} significa que entre todos los \red{positivos detectados}, la mayoría en realidad no lo son. Una \red{precisión baja} puede ocurrir cuando uno está demasiado \blue{ansioso} para \red{rechazar $H_1$.} En este caso, si \red{rechazamos la hipótesis nula}, probablemente no sea una buena decisión.

## La curva *Precision-Recall*

* El \red{recall} sería simplemente la \red{tasa de verdaderos positivos.}

* La diferencia fundamental entre la \red{precisión} y el \red{recall} es el \blue{denominador}. En el caso, de la \red{precisión}, dividimos entre todos los \red{positivos detectados}; en cambio, en el caso del \red{recall}, dividimos entre todos los \red{positivos verdaderos.}

* Un \red{recall alto} significa que la \red{regla de decisión} es muy fiable en \red{detectar positivos} o \red{rechazar la hipótesis nula $H_0$}. Esto ocurre cuando elegimos un valor $\alpha$ muy bajo. Sin embargo, en este caso, tendríamos una \red{precisión baja.}

* Un \red{recall bajo} significa que \red{aceptamos la hipótesis nula} demasiadas veces y por tanto, casi nunca detectamos un \red{positivo}. Sin embargo, tener un \red{recall bajo} significa tener una \red{precisión alta} ya que casi nunca \red{rechazamos la hipótesis nula} a no ser que tengamos \red{evidencia clara.}


## La curva *Precision-Recall*

* La \red{curva PR} consiste en realizar un gráfico de la \red{precisión} (eje $Y$) en función del \red{recall} o \red{tasa de verdaderos positivos} (eje $X$).

* La relación entre la \red{precisión} y el \red{recall} y la \red{tasa de falsos positivos} y la \red{tasa de verdaderos positivos} es la siguiente:
$$
P_{FP}=\frac{\mbox{recall}(1-\mbox{precisión})}{\mbox{precisión}},\quad P_{VP}=\mbox{recall}.
$$

## Ejemplo anterior
```{r,echo=FALSE,fig.align='center'}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
precision = tasas.verdaderos.positivos/(tasas.verdaderos.positivos+tasas.falsos.positivos)
precision[1]=1
recall = tasas.verdaderos.positivos
plot(recall,precision,type="l",xlab="Recall",ylab="Precisión",main="Curva PR",col="blue")
```

## Curva ROC ideal y decisión ciega
* La curva \red{PR} para la curva \red{ROC ideal} correspondería a los lados que van de los puntos $(0,1)$ al $(1,1)$ y del $(1,1)$ al $(1,0)$ ya que en este caso, la \red{precisión} valdría $1$ y el \red{recall} también.

* En el caso de la \red{decisión ciega}, la precisión sería:
$$
\mbox{precisión}=\frac{P_{VP}}{P_{VP}+P_{FP}}=\frac{\alpha}{\alpha +\alpha}=\frac{1}{2},
$$
y el \red{recall} valdría:
$$
\mbox{recall}=P_{VP}=\alpha.
$$
Por tanto, la curva \red{PR} correspondería a la recta horizontal $y=\frac{1}{2}$.

## Curva ROC ideal y decisión ciega
```{r,echo=FALSE,fig.align='center'}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
precision = tasas.verdaderos.positivos/(tasas.verdaderos.positivos+tasas.falsos.positivos)
precision[1]=1
recall = tasas.verdaderos.positivos
plot(recall,precision,type="l",xlab="Recall",ylab="Precisión",main="Curva PR",col="blue")
lines(c(0,1),c(0.5,0.5),col="red")
text(0.5,0.525,"Decisión ciega",col="red")
text(0.35,0.92,"Neyman-Pearson",col="blue")
```

# Código en R y python

## Código R de la curva ROC



\begin{align*}
P_{FP}& =\alpha,\\
P_{FN}&  = P(N(`r round((2.5-2)/(2/sqrt(50)),3)`,1)\leq \phi^{-1}(1-\alpha))=\phi(\phi^{-1}(1-\alpha)-`r round((2.5-2)/(2/sqrt(50)),3)`),\\
P_{VP}& =1-P_{FN}=1-\phi(\phi^{-1}(1-\alpha)-`r round((2.5-2)/(2/sqrt(50)),3)`).
\end{align*}

```{r,eval=FALSE}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 
  1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,
     type="l",xlab=expression(P[FP]),
     ylab=expression(P[VP]),main="Curva ROC",col="red")
```


## Código R de la curva ROC

```{r,echo=FALSE}
alphas = seq(from=0,to=1,by=0.01)
tasas.falsos.positivos=alphas
tasas.verdaderos.positivos = 1-pnorm(qnorm(1-alphas)-(2.5-2)/(2/sqrt(50)))
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,type="l",xlab=expression(P[FP]),ylab=expression(P[VP]),main="Curva ROC",col="red")
```


## Código R de la curva ROC y decisión ciega

```{r,eval=FALSE}
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,
     type="l",xlab=expression(P[FP]),
     ylab=expression(P[VP]),main="Curva ROC",col="blue")
text(0.25,0.75,"Neyman-Pearson",col="blue")
lines(c(0,1),c(0,1),col="red")
text(0.5,0.45,srt=33,"Decisión ciega",col="red")
```


## Código R de la curva ROC y decisión ciega

```{r,echo=FALSE}
plot(tasas.falsos.positivos,tasas.verdaderos.positivos,type="l",xlab=expression(P[FP]),ylab=expression(P[VP]),main="Curva ROC",col="blue")
text(0.25,0.75,"Neyman-Pearson",col="blue")
lines(c(0,1),c(0,1),col="red")
text(0.5,0.45,srt=33,"Decisión ciega",col="red")
```

## Código R de la curva PR

```{r,eval=FALSE,fig.align='center'}
precision = tasas.verdaderos.positivos/
  (tasas.verdaderos.positivos+tasas.falsos.positivos)
precision[1]=1
recall = tasas.verdaderos.positivos
plot(recall,precision,type="l",xlab="Recall",
     ylab="Precisión",main="Curva PR",col="blue")
```

## Código R de la curva PR

```{r,echo=FALSE,fig.align='center'}
precision = tasas.verdaderos.positivos/
  (tasas.verdaderos.positivos+tasas.falsos.positivos)
precision[1]=1
recall = tasas.verdaderos.positivos
plot(recall,precision,type="l",xlab="Recall",
     ylab="Precisión",main="Curva PR",col="blue")
```

## Código R de la curva PR y Decisión ciega

```{r,eval=FALSE,fig.align='center'}
plot(recall,precision,type="l",xlab="Recall",
     ylab="Precisión",main="Curva PR",col="blue")
lines(c(0,1),c(0.5,0.5),col="red")
text(0.5,0.525,"Decisión ciega",col="red")
text(0.35,0.92,"Neyman-Pearson",col="blue")
```

## Código R de la curva PR y Decisión ciega

```{r,echo=FALSE,fig.align='center'}
plot(recall,precision,type="l",xlab="Recall",
     ylab="Precisión",main="Curva PR",col="blue")
lines(c(0,1),c(0.5,0.5),col="red")
text(0.5,0.525,"Decisión ciega",col="red")
text(0.35,0.92,"Neyman-Pearson",col="blue")
```


## Código python de la curva ROC

```{python,eval=F}
import numpy
from scipy.stats import norm
import math
import matplotlib.pyplot as plt
alphas = numpy.linspace(0,1,100)
tfp =alphas
media = (2.5-2)/(2/math.sqrt(50))
tvp = 1-norm.cdf(norm.ppf(1-tfp)-media)
plt.title("Curva ROC")
plt.xlabel("Falsos positivos")
plt.ylabel("Verdaderos positivos")
plt.plot(tfp,tvp, 
  c = "blue", ls = "-",marker = "o")
plt.show()
```


## Código python de la curva ROC

```{python,echo=F}
import numpy
from scipy.stats import norm
import math
import matplotlib.pyplot as plt
alphas = numpy.linspace(0,1,100)
tfp =alphas
media = (2.5-2)/(2/math.sqrt(50))
tvp = 1-norm.cdf(norm.ppf(1-tfp)-media)
plt.title("Curva ROC")
plt.xlabel("Falsos positivos")
plt.ylabel("Verdaderos positivos")
plt.plot(tfp,tvp, 
  c = "blue", ls = "-",marker = "o")
plt.show()
```

## Código python de la curva ROC y decisión ciega

```{python,eval=F}
plt.title("Curva ROC")
plt.xlabel("Falsos positivos")
plt.ylabel("Verdaderos positivos")
plt.plot(tfp,tvp, 
   c = "blue", ls = "-", marker = "o")
plt.plot(tfp,tfp,c="red")
plt.text(0.25,0.75,"Neyman-Pearson",c="blue")
plt.text(0.5,0.45,"Decisión ciega",c="red")
plt.show()
```

## Código python de la curva ROC y decisión ciega

```{python,echo=F}
plt.title("Curva ROC")
plt.xlabel("Falsos positivos")
plt.ylabel("Verdaderos positivos")
plt.plot(tfp,tvp, 
   c = "blue", ls = "-", marker = "o")
plt.plot(tfp,tfp,c="red")
plt.text(0.25,0.75,"Neyman-Pearson",c="blue")
plt.text(0.5,0.45,"Decisión ciega",c="red")
plt.show()
```

## Código python de la curva PR

```{python,eval=F}
tvp[0]=1
precision = tvp/(tvp+tfp)
recall = tvp
recall[0]=0
plt.title("Curva PR")
plt.xlabel("Recall")
plt.ylabel("Precisión")
plt.plot(recall,precision, 
   c = "blue", ls = "-", marker = "o")
```



## Código python de la curva PR

```{python,echo=F}
tvp[0]=1
precision = tvp/(tvp+tfp)
recall = tvp
recall[0]=0
plt.title("Curva PR")
plt.xlabel("Recall")
plt.ylabel("Precisión")
plt.plot(recall,precision, 
   c = "blue", ls = "-", marker = "o")
```


## Código python de la curva PR y Decisión ciega

```{python,eval=F}
tvp[0]=1
precision = tvp/(tvp+tfp)
recall = tvp
recall[0]=0
plt.title("Curva PR")
plt.xlabel("Recall")
plt.ylabel("Precisión")
plt.plot(recall,precision, 
   c = "blue", ls = "-", marker = "o")
recall_ciega = [0,1]
precision_ciega = [0.5,0.5]
plt.plot(recall_ciega,precision_ciega,c="red",ls="-",
  marker="o")
plt.text(0.35,0.9,"Neyman-Pearson",c="blue")
plt.text(0.5,0.515,"Decisión ciega",c="red")
```

## Código python de la curva PR y Decisión ciega

```{python,echo=F}
tvp[0]=1
precision = tvp/(tvp+tfp)
recall = tvp
recall[0]=0
plt.title("Curva PR")
plt.xlabel("Recall")
plt.ylabel("Precisión")
plt.plot(recall,precision, 
   c = "blue", ls = "-", marker = "o")
recall_ciega = [0,1]
precision_ciega = [0.5,0.5]
plt.plot(recall_ciega,precision_ciega,c="red",ls="-",marker="o")
plt.text(0.35,0.9,"Neyman-Pearson",c="blue")
plt.text(0.5,0.515,"Decisión ciega",c="red")
```